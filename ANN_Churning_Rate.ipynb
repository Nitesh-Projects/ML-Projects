{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Churning_Rate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnnJfdU/v2DXmm37Yuk1UX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nitesh-Projects/ML-Projects/blob/master/ANN_Churning_Rate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZcJP4VwqJeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAXUifrbqTde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeuP7c32q748",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HlvGk6hsNMT",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1be01f0e-972c-4f8e-b73c-2a614bf89ab1"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f0ce034f-22a7-46ad-975e-668717f6e4a1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f0ce034f-22a7-46ad-975e-668717f6e4a1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ANN_Churn_Modelling.csv to ANN_Churn_Modelling.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_d2GhNTsd2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "df2 = pd.read_csv(io.BytesIO(uploaded['ANN_Churn_Modelling.csv']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa-kPRR9vmfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ae2ace96-f1b4-485d-94b0-a827834fb69d"
      },
      "source": [
        "df2.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gNF3Px4yPiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66448f7f-0e36-4439-825b-ed1eb9937e05"
      },
      "source": [
        "df2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ0U43x7ySzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "80a9d996-a29f-468c-b2ae-4ff0be9ff036"
      },
      "source": [
        "df2.isnull().sum(axis = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RowNumber          0\n",
              "CustomerId         0\n",
              "Surname            0\n",
              "CreditScore        0\n",
              "Geography          0\n",
              "Gender             0\n",
              "Age                0\n",
              "Tenure             0\n",
              "Balance            0\n",
              "NumOfProducts      0\n",
              "HasCrCard          0\n",
              "IsActiveMember     0\n",
              "EstimatedSalary    0\n",
              "Exited             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgDGghXNybXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df2.iloc[:,3:13]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPd5B2Lcysoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3f36dd45-91c2-4e22-a44f-f62edd5aca5f"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
              "0          619    France  Female  ...          1               1        101348.88\n",
              "1          608     Spain  Female  ...          0               1        112542.58\n",
              "2          502    France  Female  ...          1               0        113931.57\n",
              "3          699    France  Female  ...          0               0         93826.63\n",
              "4          850     Spain  Female  ...          1               1         79084.10\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDzN0-zUyxp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df2.iloc[:,13]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSstkGFKzEz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d5528826-5599-4a07-f02d-f635fcb13955"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "9995    0\n",
              "9996    0\n",
              "9997    1\n",
              "9998    1\n",
              "9999    0\n",
              "Name: Exited, Length: 10000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu1gziY3zGHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Geography = pd.get_dummies(x['Geography'],drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRELIlFezzRX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "08132575-7746-4107-b39f-9b3ed1d5cccb"
      },
      "source": [
        "Geography"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Germany  Spain\n",
              "0           0      0\n",
              "1           0      1\n",
              "2           0      0\n",
              "3           0      0\n",
              "4           0      1\n",
              "...       ...    ...\n",
              "9995        0      0\n",
              "9996        0      0\n",
              "9997        0      0\n",
              "9998        1      0\n",
              "9999        0      0\n",
              "\n",
              "[10000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLSQsNWyz06Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gender=pd.get_dummies(x['Gender'],drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWj6z0sSz-bk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "998156dd-59d4-4772-ddc5-383b8c3c2b71"
      },
      "source": [
        "gender"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Male\n",
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "...    ...\n",
              "9995     1\n",
              "9996     1\n",
              "9997     0\n",
              "9998     1\n",
              "9999     0\n",
              "\n",
              "[10000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4x-Q0PP0CNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = pd.concat([x,Geography,gender],axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvu0611i0XdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6539952d-9b26-497a-f17a-c20ae964fc87"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  Age  ...  EstimatedSalary  Germany  Spain  Male\n",
              "0          619    France  Female   42  ...        101348.88        0      0     0\n",
              "1          608     Spain  Female   41  ...        112542.58        0      1     0\n",
              "2          502    France  Female   42  ...        113931.57        0      0     0\n",
              "3          699    France  Female   39  ...         93826.63        0      0     0\n",
              "4          850     Spain  Female   43  ...         79084.10        0      1     0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr7nlz3H0ZCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.drop(['Geography','Gender'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVYi2gxx0qLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e60359ce-5238-4cd1-d4a9-9360ac39fb7d"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Age  Tenure    Balance  ...  EstimatedSalary  Germany  Spain  Male\n",
              "0          619   42       2       0.00  ...        101348.88        0      0     0\n",
              "1          608   41       1   83807.86  ...        112542.58        0      1     0\n",
              "2          502   42       8  159660.80  ...        113931.57        0      0     0\n",
              "3          699   39       1       0.00  ...         93826.63        0      0     0\n",
              "4          850   43       2  125510.82  ...         79084.10        0      1     0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwCfWirM0sQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS8APFg21CKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZQDn0N-1hwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoskzsS41xs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1ebSKZb2EYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = sc.fit_transform(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAfkriLJ2Q_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "75db155d-b503-4ef0-cf53-7a3fc26d5172"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.16958176, -0.46460796,  0.00666099, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       [-2.30455945,  0.30102557, -1.37744033, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-1.19119591, -0.94312892, -1.031415  , ..., -0.5698444 ,\n",
              "        -0.57369368, -1.09168714],\n",
              "       ...,\n",
              "       [ 0.9015152 , -0.36890377,  0.00666099, ..., -0.5698444 ,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-0.62420521, -0.08179119,  1.39076231, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       [-0.28401079,  0.87525072, -1.37744033, ...,  1.75486502,\n",
              "        -0.57369368, -1.09168714]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzrGoKnu2TLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = sc.fit_transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ShSEIv2bJy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b291f1c1-18cd-41fe-9422-9ad42f782bf2"
      },
      "source": [
        "x_test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.56129438, -0.39401698,  0.9869706 , ...,  1.62776996,\n",
              "        -0.57427105, -1.11339196],\n",
              "       [-1.33847768,  0.07611425, -1.08432132, ..., -0.61433742,\n",
              "        -0.57427105, -1.11339196],\n",
              "       [ 0.58347561,  0.26416674,  0.9869706 , ..., -0.61433742,\n",
              "         1.74133801, -1.11339196],\n",
              "       ...,\n",
              "       [-0.76084144, -0.29999074, -1.42953664, ..., -0.61433742,\n",
              "         1.74133801,  0.8981563 ],\n",
              "       [-0.0046631 , -0.48804323, -0.39389068, ...,  1.62776996,\n",
              "        -0.57427105,  0.8981563 ],\n",
              "       [-0.81335383, -0.86414821,  0.9869706 , ...,  1.62776996,\n",
              "        -0.57427105,  0.8981563 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQKx62Ab2dAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxRHIfAu2jCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlu4Mg6L2vXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdIPvCZZ231h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LeakyReLU,PReLU,ELU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agqGIvYG3Cjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVi4qZ0J3Kcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialising the ANN\n",
        "classifier = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lktb5cQ13ObF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 6,  kernel_initializer='he_uniform',activation='relu',input_dim = 11   ))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnQlA0HUgeEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer= 'he_uniform',activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D49B826mESR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1,  kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ96z_0mmO8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b9b695c6-d84f-40d0-a7ca-d7e64fdfb257"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWMVzlRPmtBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FQJKIKJnP_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f8ff973-3a5e-4241-9ddc-b006982e5171"
      },
      "source": [
        "\n",
        "# Fitting the ANN to the Training set\n",
        "model_history=classifier.fit(x_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.6096 - accuracy: 0.7470 - val_loss: 0.5491 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7962 - val_loss: 0.5147 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.5096 - accuracy: 0.7962 - val_loss: 0.4973 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4925 - accuracy: 0.7962 - val_loss: 0.4847 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4794 - accuracy: 0.7964 - val_loss: 0.4749 - val_accuracy: 0.7959\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4680 - accuracy: 0.7974 - val_loss: 0.4658 - val_accuracy: 0.7970\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4574 - accuracy: 0.8009 - val_loss: 0.4579 - val_accuracy: 0.8008\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4482 - accuracy: 0.8063 - val_loss: 0.4514 - val_accuracy: 0.8061\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4410 - accuracy: 0.8071 - val_loss: 0.4469 - val_accuracy: 0.8088\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4352 - accuracy: 0.8112 - val_loss: 0.4432 - val_accuracy: 0.8080\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4308 - accuracy: 0.8164 - val_loss: 0.4406 - val_accuracy: 0.8084\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4277 - accuracy: 0.8179 - val_loss: 0.4384 - val_accuracy: 0.8111\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4248 - accuracy: 0.8188 - val_loss: 0.4368 - val_accuracy: 0.8107\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4228 - accuracy: 0.8188 - val_loss: 0.4356 - val_accuracy: 0.8084\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4211 - accuracy: 0.8186 - val_loss: 0.4346 - val_accuracy: 0.8099\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4193 - accuracy: 0.8199 - val_loss: 0.4337 - val_accuracy: 0.8088\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4181 - accuracy: 0.8203 - val_loss: 0.4324 - val_accuracy: 0.8107\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4168 - accuracy: 0.8197 - val_loss: 0.4319 - val_accuracy: 0.8111\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4159 - accuracy: 0.8214 - val_loss: 0.4308 - val_accuracy: 0.8118\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4150 - accuracy: 0.8224 - val_loss: 0.4301 - val_accuracy: 0.8137\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4137 - accuracy: 0.8231 - val_loss: 0.4291 - val_accuracy: 0.8122\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4134 - accuracy: 0.8233 - val_loss: 0.4286 - val_accuracy: 0.8137\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4127 - accuracy: 0.8238 - val_loss: 0.4282 - val_accuracy: 0.8133\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4118 - accuracy: 0.8233 - val_loss: 0.4276 - val_accuracy: 0.8137\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4112 - accuracy: 0.8240 - val_loss: 0.4271 - val_accuracy: 0.8148\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4107 - accuracy: 0.8261 - val_loss: 0.4266 - val_accuracy: 0.8137\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4100 - accuracy: 0.8252 - val_loss: 0.4258 - val_accuracy: 0.8175\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4095 - accuracy: 0.8265 - val_loss: 0.4256 - val_accuracy: 0.8148\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4091 - accuracy: 0.8268 - val_loss: 0.4247 - val_accuracy: 0.8145\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4086 - accuracy: 0.8278 - val_loss: 0.4241 - val_accuracy: 0.8167\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4081 - accuracy: 0.8280 - val_loss: 0.4234 - val_accuracy: 0.8171\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4077 - accuracy: 0.8270 - val_loss: 0.4227 - val_accuracy: 0.8179\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4072 - accuracy: 0.8285 - val_loss: 0.4221 - val_accuracy: 0.8183\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4067 - accuracy: 0.8294 - val_loss: 0.4220 - val_accuracy: 0.8175\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4062 - accuracy: 0.8296 - val_loss: 0.4213 - val_accuracy: 0.8198\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4058 - accuracy: 0.8287 - val_loss: 0.4207 - val_accuracy: 0.8194\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4056 - accuracy: 0.8311 - val_loss: 0.4199 - val_accuracy: 0.8198\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4051 - accuracy: 0.8308 - val_loss: 0.4196 - val_accuracy: 0.8220\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4045 - accuracy: 0.8300 - val_loss: 0.4188 - val_accuracy: 0.8217\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4044 - accuracy: 0.8306 - val_loss: 0.4182 - val_accuracy: 0.8213\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4041 - accuracy: 0.8311 - val_loss: 0.4182 - val_accuracy: 0.8220\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4037 - accuracy: 0.8308 - val_loss: 0.4177 - val_accuracy: 0.8209\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4035 - accuracy: 0.8330 - val_loss: 0.4179 - val_accuracy: 0.8209\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4033 - accuracy: 0.8315 - val_loss: 0.4170 - val_accuracy: 0.8213\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4030 - accuracy: 0.8334 - val_loss: 0.4170 - val_accuracy: 0.8232\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4028 - accuracy: 0.8319 - val_loss: 0.4167 - val_accuracy: 0.8205\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4026 - accuracy: 0.8326 - val_loss: 0.4169 - val_accuracy: 0.8209\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4023 - accuracy: 0.8304 - val_loss: 0.4161 - val_accuracy: 0.8220\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4022 - accuracy: 0.8336 - val_loss: 0.4160 - val_accuracy: 0.8224\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4020 - accuracy: 0.8332 - val_loss: 0.4157 - val_accuracy: 0.8243\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4018 - accuracy: 0.8332 - val_loss: 0.4158 - val_accuracy: 0.8243\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4015 - accuracy: 0.8322 - val_loss: 0.4152 - val_accuracy: 0.8220\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4014 - accuracy: 0.8324 - val_loss: 0.4156 - val_accuracy: 0.8236\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8326 - val_loss: 0.4148 - val_accuracy: 0.8243\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4010 - accuracy: 0.8322 - val_loss: 0.4150 - val_accuracy: 0.8220\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8326 - val_loss: 0.4143 - val_accuracy: 0.8209\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4007 - accuracy: 0.8337 - val_loss: 0.4140 - val_accuracy: 0.8217\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4005 - accuracy: 0.8337 - val_loss: 0.4139 - val_accuracy: 0.8239\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4003 - accuracy: 0.8334 - val_loss: 0.4133 - val_accuracy: 0.8224\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4002 - accuracy: 0.8324 - val_loss: 0.4136 - val_accuracy: 0.8243\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4000 - accuracy: 0.8317 - val_loss: 0.4129 - val_accuracy: 0.8236\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3998 - accuracy: 0.8337 - val_loss: 0.4132 - val_accuracy: 0.8258\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3998 - accuracy: 0.8326 - val_loss: 0.4131 - val_accuracy: 0.8251\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3996 - accuracy: 0.8330 - val_loss: 0.4125 - val_accuracy: 0.8247\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3995 - accuracy: 0.8328 - val_loss: 0.4123 - val_accuracy: 0.8232\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3994 - accuracy: 0.8326 - val_loss: 0.4122 - val_accuracy: 0.8236\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3992 - accuracy: 0.8322 - val_loss: 0.4121 - val_accuracy: 0.8254\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3990 - accuracy: 0.8326 - val_loss: 0.4116 - val_accuracy: 0.8236\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3990 - accuracy: 0.8330 - val_loss: 0.4114 - val_accuracy: 0.8239\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3988 - accuracy: 0.8337 - val_loss: 0.4117 - val_accuracy: 0.8270\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3985 - accuracy: 0.8330 - val_loss: 0.4109 - val_accuracy: 0.8243\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3984 - accuracy: 0.8337 - val_loss: 0.4114 - val_accuracy: 0.8251\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3983 - accuracy: 0.8345 - val_loss: 0.4111 - val_accuracy: 0.8243\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3981 - accuracy: 0.8347 - val_loss: 0.4109 - val_accuracy: 0.8254\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3980 - accuracy: 0.8341 - val_loss: 0.4105 - val_accuracy: 0.8251\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3978 - accuracy: 0.8354 - val_loss: 0.4105 - val_accuracy: 0.8262\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3975 - accuracy: 0.8352 - val_loss: 0.4107 - val_accuracy: 0.8281\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3976 - accuracy: 0.8349 - val_loss: 0.4099 - val_accuracy: 0.8258\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3972 - accuracy: 0.8349 - val_loss: 0.4096 - val_accuracy: 0.8262\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3971 - accuracy: 0.8356 - val_loss: 0.4098 - val_accuracy: 0.8273\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3968 - accuracy: 0.8352 - val_loss: 0.4089 - val_accuracy: 0.8254\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3965 - accuracy: 0.8356 - val_loss: 0.4096 - val_accuracy: 0.8285\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3965 - accuracy: 0.8349 - val_loss: 0.4081 - val_accuracy: 0.8266\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3960 - accuracy: 0.8350 - val_loss: 0.4074 - val_accuracy: 0.8270\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3958 - accuracy: 0.8354 - val_loss: 0.4075 - val_accuracy: 0.8277\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3957 - accuracy: 0.8358 - val_loss: 0.4071 - val_accuracy: 0.8277\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3954 - accuracy: 0.8341 - val_loss: 0.4071 - val_accuracy: 0.8277\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3949 - accuracy: 0.8356 - val_loss: 0.4065 - val_accuracy: 0.8285\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3949 - accuracy: 0.8350 - val_loss: 0.4062 - val_accuracy: 0.8285\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8343 - val_loss: 0.4051 - val_accuracy: 0.8292\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3940 - accuracy: 0.8350 - val_loss: 0.4048 - val_accuracy: 0.8289\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3938 - accuracy: 0.8364 - val_loss: 0.4043 - val_accuracy: 0.8289\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3934 - accuracy: 0.8360 - val_loss: 0.4045 - val_accuracy: 0.8311\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3932 - accuracy: 0.8364 - val_loss: 0.4042 - val_accuracy: 0.8311\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3925 - accuracy: 0.8377 - val_loss: 0.4034 - val_accuracy: 0.8296\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3924 - accuracy: 0.8352 - val_loss: 0.4033 - val_accuracy: 0.8319\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3919 - accuracy: 0.8352 - val_loss: 0.4027 - val_accuracy: 0.8319\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3912 - accuracy: 0.8367 - val_loss: 0.4016 - val_accuracy: 0.8311\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3908 - accuracy: 0.8367 - val_loss: 0.4016 - val_accuracy: 0.8323\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3901 - accuracy: 0.8365 - val_loss: 0.4010 - val_accuracy: 0.8330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5GBFpOHnSsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training accuracy = 83.6 and accuracy of model = 83.30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FehZwHhoTxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 6,  kernel_initializer='uniform',activation='relu',input_dim = 11   ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hslVBGEupRJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the input layer and the 2nd hidden layer\n",
        "classifier.add(Dense(units = 6,  kernel_initializer='uniform',activation='relu' ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGCN0A59pYMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1,  kernel_initializer = 'uniform', activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp_jm0W2pdb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTI5xkL3plmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bd652f5-bef8-46ba-ef3d-64f9b29ce294"
      },
      "source": [
        "# Fitting the ANN to the Training set\n",
        "model_history=classifier.fit(x_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.6265 - accuracy: 0.7962 - val_loss: 0.5543 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.5191 - accuracy: 0.7962 - val_loss: 0.5072 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5060 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.5050 - accuracy: 0.7962 - val_loss: 0.5055 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.5044 - accuracy: 0.7962 - val_loss: 0.5049 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.5033 - accuracy: 0.7962 - val_loss: 0.5031 - val_accuracy: 0.7955\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4998 - accuracy: 0.7962 - val_loss: 0.4984 - val_accuracy: 0.7955\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4928 - accuracy: 0.7962 - val_loss: 0.4918 - val_accuracy: 0.7955\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4854 - accuracy: 0.7962 - val_loss: 0.4845 - val_accuracy: 0.7955\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4771 - accuracy: 0.7962 - val_loss: 0.4772 - val_accuracy: 0.7955\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4696 - accuracy: 0.7962 - val_loss: 0.4698 - val_accuracy: 0.7955\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4613 - accuracy: 0.7962 - val_loss: 0.4626 - val_accuracy: 0.7955\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4538 - accuracy: 0.7962 - val_loss: 0.4552 - val_accuracy: 0.7955\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4462 - accuracy: 0.7962 - val_loss: 0.4488 - val_accuracy: 0.7955\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4395 - accuracy: 0.7962 - val_loss: 0.4431 - val_accuracy: 0.7955\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4329 - accuracy: 0.7962 - val_loss: 0.4368 - val_accuracy: 0.7955\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4271 - accuracy: 0.7962 - val_loss: 0.4327 - val_accuracy: 0.7955\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4224 - accuracy: 0.7962 - val_loss: 0.4288 - val_accuracy: 0.7955\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4184 - accuracy: 0.7962 - val_loss: 0.4258 - val_accuracy: 0.7955\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.7962 - val_loss: 0.4228 - val_accuracy: 0.7955\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4112 - accuracy: 0.7962 - val_loss: 0.4204 - val_accuracy: 0.7967\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4088 - accuracy: 0.8220 - val_loss: 0.4188 - val_accuracy: 0.8217\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4069 - accuracy: 0.8291 - val_loss: 0.4173 - val_accuracy: 0.8224\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4054 - accuracy: 0.8321 - val_loss: 0.4163 - val_accuracy: 0.8236\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4042 - accuracy: 0.8330 - val_loss: 0.4151 - val_accuracy: 0.8232\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4030 - accuracy: 0.8326 - val_loss: 0.4136 - val_accuracy: 0.8266\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4018 - accuracy: 0.8345 - val_loss: 0.4126 - val_accuracy: 0.8251\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8350 - val_loss: 0.4112 - val_accuracy: 0.8262\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3994 - accuracy: 0.8343 - val_loss: 0.4099 - val_accuracy: 0.8266\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3981 - accuracy: 0.8339 - val_loss: 0.4087 - val_accuracy: 0.8273\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3969 - accuracy: 0.8343 - val_loss: 0.4075 - val_accuracy: 0.8262\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3960 - accuracy: 0.8339 - val_loss: 0.4061 - val_accuracy: 0.8277\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3947 - accuracy: 0.8349 - val_loss: 0.4051 - val_accuracy: 0.8270\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3935 - accuracy: 0.8339 - val_loss: 0.4040 - val_accuracy: 0.8273\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3926 - accuracy: 0.8341 - val_loss: 0.4030 - val_accuracy: 0.8273\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3915 - accuracy: 0.8336 - val_loss: 0.4021 - val_accuracy: 0.8285\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3906 - accuracy: 0.8339 - val_loss: 0.4011 - val_accuracy: 0.8266\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3896 - accuracy: 0.8343 - val_loss: 0.4002 - val_accuracy: 0.8289\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3885 - accuracy: 0.8343 - val_loss: 0.3992 - val_accuracy: 0.8285\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3876 - accuracy: 0.8339 - val_loss: 0.3984 - val_accuracy: 0.8285\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3867 - accuracy: 0.8332 - val_loss: 0.3976 - val_accuracy: 0.8300\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3858 - accuracy: 0.8337 - val_loss: 0.3965 - val_accuracy: 0.8300\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3850 - accuracy: 0.8339 - val_loss: 0.3957 - val_accuracy: 0.8304\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3839 - accuracy: 0.8350 - val_loss: 0.3948 - val_accuracy: 0.8319\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3831 - accuracy: 0.8364 - val_loss: 0.3943 - val_accuracy: 0.8326\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3821 - accuracy: 0.8375 - val_loss: 0.3935 - val_accuracy: 0.8417\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3813 - accuracy: 0.8390 - val_loss: 0.3925 - val_accuracy: 0.8440\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3805 - accuracy: 0.8388 - val_loss: 0.3919 - val_accuracy: 0.8432\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3795 - accuracy: 0.8416 - val_loss: 0.3913 - val_accuracy: 0.8436\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3791 - accuracy: 0.8412 - val_loss: 0.3905 - val_accuracy: 0.8451\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3783 - accuracy: 0.8421 - val_loss: 0.3896 - val_accuracy: 0.8444\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3773 - accuracy: 0.8440 - val_loss: 0.3892 - val_accuracy: 0.8440\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3767 - accuracy: 0.8447 - val_loss: 0.3884 - val_accuracy: 0.8448\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3761 - accuracy: 0.8434 - val_loss: 0.3879 - val_accuracy: 0.8440\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3753 - accuracy: 0.8440 - val_loss: 0.3876 - val_accuracy: 0.8466\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3745 - accuracy: 0.8446 - val_loss: 0.3870 - val_accuracy: 0.8470\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3739 - accuracy: 0.8446 - val_loss: 0.3864 - val_accuracy: 0.8470\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3732 - accuracy: 0.8446 - val_loss: 0.3857 - val_accuracy: 0.8448\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3724 - accuracy: 0.8442 - val_loss: 0.3849 - val_accuracy: 0.8448\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3717 - accuracy: 0.8449 - val_loss: 0.3844 - val_accuracy: 0.8463\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3712 - accuracy: 0.8464 - val_loss: 0.3837 - val_accuracy: 0.8432\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3703 - accuracy: 0.8461 - val_loss: 0.3831 - val_accuracy: 0.8436\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3698 - accuracy: 0.8470 - val_loss: 0.3830 - val_accuracy: 0.8440\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3696 - accuracy: 0.8475 - val_loss: 0.3823 - val_accuracy: 0.8425\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3686 - accuracy: 0.8464 - val_loss: 0.3817 - val_accuracy: 0.8440\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3679 - accuracy: 0.8487 - val_loss: 0.3813 - val_accuracy: 0.8436\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3671 - accuracy: 0.8447 - val_loss: 0.3806 - val_accuracy: 0.8436\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3664 - accuracy: 0.8459 - val_loss: 0.3807 - val_accuracy: 0.8463\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3658 - accuracy: 0.8462 - val_loss: 0.3795 - val_accuracy: 0.8440\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3654 - accuracy: 0.8485 - val_loss: 0.3786 - val_accuracy: 0.8470\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3644 - accuracy: 0.8477 - val_loss: 0.3781 - val_accuracy: 0.8466\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3638 - accuracy: 0.8481 - val_loss: 0.3778 - val_accuracy: 0.8470\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3636 - accuracy: 0.8489 - val_loss: 0.3773 - val_accuracy: 0.8448\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3629 - accuracy: 0.8489 - val_loss: 0.3767 - val_accuracy: 0.8455\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3620 - accuracy: 0.8505 - val_loss: 0.3771 - val_accuracy: 0.8466\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3614 - accuracy: 0.8530 - val_loss: 0.3765 - val_accuracy: 0.8482\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3606 - accuracy: 0.8515 - val_loss: 0.3770 - val_accuracy: 0.8470\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3599 - accuracy: 0.8503 - val_loss: 0.3748 - val_accuracy: 0.8474\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3597 - accuracy: 0.8515 - val_loss: 0.3738 - val_accuracy: 0.8489\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3584 - accuracy: 0.8539 - val_loss: 0.3740 - val_accuracy: 0.8501\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3580 - accuracy: 0.8531 - val_loss: 0.3733 - val_accuracy: 0.8512\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3572 - accuracy: 0.8550 - val_loss: 0.3729 - val_accuracy: 0.8493\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3566 - accuracy: 0.8548 - val_loss: 0.3725 - val_accuracy: 0.8504\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3558 - accuracy: 0.8552 - val_loss: 0.3716 - val_accuracy: 0.8508\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3552 - accuracy: 0.8569 - val_loss: 0.3719 - val_accuracy: 0.8493\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3551 - accuracy: 0.8556 - val_loss: 0.3711 - val_accuracy: 0.8516\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3541 - accuracy: 0.8545 - val_loss: 0.3720 - val_accuracy: 0.8504\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3539 - accuracy: 0.8550 - val_loss: 0.3701 - val_accuracy: 0.8501\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3533 - accuracy: 0.8558 - val_loss: 0.3702 - val_accuracy: 0.8493\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3526 - accuracy: 0.8582 - val_loss: 0.3699 - val_accuracy: 0.8512\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3523 - accuracy: 0.8565 - val_loss: 0.3694 - val_accuracy: 0.8497\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3510 - accuracy: 0.8567 - val_loss: 0.3689 - val_accuracy: 0.8516\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3510 - accuracy: 0.8582 - val_loss: 0.3689 - val_accuracy: 0.8497\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3505 - accuracy: 0.8587 - val_loss: 0.3676 - val_accuracy: 0.8535\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3499 - accuracy: 0.8567 - val_loss: 0.3673 - val_accuracy: 0.8538\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3497 - accuracy: 0.8589 - val_loss: 0.3678 - val_accuracy: 0.8531\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3494 - accuracy: 0.8580 - val_loss: 0.3679 - val_accuracy: 0.8519\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3486 - accuracy: 0.8587 - val_loss: 0.3678 - val_accuracy: 0.8516\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3488 - accuracy: 0.8614 - val_loss: 0.3679 - val_accuracy: 0.8523\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 1ms/step - loss: 0.3484 - accuracy: 0.8606 - val_loss: 0.3675 - val_accuracy: 0.8527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPbSohw1ptIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train accuracy: 0.8606  val_accuracy: 0.8527\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koXcCU67qNn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now trying to add more hidden layers to increase further accuracy 1st hidden layer with 10 nuerons\n",
        "classifier.add(Dense( units = 10 , kernel_initializer = 'uniform',activation = 'relu',input_dim =11))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq5xunOQqxLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2st hidden layer with 15 nuerons\n",
        "classifier.add(Dense( units = 15 , kernel_initializer = 'uniform',activation = 'relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs_cX5wXrM6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3rd hidden layer with 10 nuerons\n",
        "classifier.add(Dense( units = 10 , kernel_initializer = 'uniform',activation = 'relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPu4OzDUrTfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile(optimizer='Adamax',loss= 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHVf4icer0EB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a77ca4d-3a63-4ff3-9776-1a869854840a"
      },
      "source": [
        "# Fitting the ANN to the Training set\n",
        "model_history2=classifier.fit(x_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 2.2858 - accuracy: 0.7962 - val_loss: 2.1946 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.9979 - accuracy: 0.7962 - val_loss: 1.9483 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.9231 - accuracy: 0.7962 - val_loss: 1.9145 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.8855 - accuracy: 0.7962 - val_loss: 1.8659 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.8299 - accuracy: 0.7962 - val_loss: 1.8192 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7979 - accuracy: 0.2030 - val_loss: 1.7992 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7779 - accuracy: 0.0000e+00 - val_loss: 1.7868 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7676 - accuracy: 0.0000e+00 - val_loss: 1.7824 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7622 - accuracy: 0.0000e+00 - val_loss: 1.7769 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7583 - accuracy: 0.0000e+00 - val_loss: 1.7722 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7540 - accuracy: 0.0000e+00 - val_loss: 1.7683 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7490 - accuracy: 0.0000e+00 - val_loss: 1.7646 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7451 - accuracy: 0.0000e+00 - val_loss: 1.7607 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7426 - accuracy: 0.0000e+00 - val_loss: 1.7588 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7403 - accuracy: 0.0026 - val_loss: 1.7573 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7394 - accuracy: 0.0179 - val_loss: 1.7577 - val_accuracy: 0.1303\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7386 - accuracy: 0.0424 - val_loss: 1.7580 - val_accuracy: 0.1053\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7388 - accuracy: 0.0795 - val_loss: 1.7586 - val_accuracy: 0.0837\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7387 - accuracy: 0.0636 - val_loss: 1.7580 - val_accuracy: 0.0333\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7384 - accuracy: 0.0237 - val_loss: 1.7622 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7383 - accuracy: 0.0049 - val_loss: 1.7575 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7384 - accuracy: 1.8660e-04 - val_loss: 1.7572 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7393 - accuracy: 0.0103 - val_loss: 1.7567 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7385 - accuracy: 0.0075 - val_loss: 1.7573 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7385 - accuracy: 3.7320e-04 - val_loss: 1.7563 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7383 - accuracy: 0.0095 - val_loss: 1.7595 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7388 - accuracy: 0.0325 - val_loss: 1.7575 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7385 - accuracy: 0.0293 - val_loss: 1.7563 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7384 - accuracy: 0.0017 - val_loss: 1.7573 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7385 - accuracy: 0.0000e+00 - val_loss: 1.7581 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7385 - accuracy: 0.0000e+00 - val_loss: 1.7562 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7387 - accuracy: 0.0103 - val_loss: 1.7565 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7383 - accuracy: 0.0000e+00 - val_loss: 1.7564 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7380 - accuracy: 0.0000e+00 - val_loss: 1.7564 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7385 - accuracy: 0.0080 - val_loss: 1.7567 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7386 - accuracy: 0.0909 - val_loss: 1.7563 - val_accuracy: 0.5964\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7392 - accuracy: 0.4952 - val_loss: 1.7572 - val_accuracy: 0.3041\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7381 - accuracy: 0.1989 - val_loss: 1.7561 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7382 - accuracy: 0.1635 - val_loss: 1.7556 - val_accuracy: 0.6622\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7380 - accuracy: 0.0603 - val_loss: 1.7566 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7383 - accuracy: 0.2034 - val_loss: 1.7559 - val_accuracy: 0.5763\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7384 - accuracy: 0.2142 - val_loss: 1.7588 - val_accuracy: 0.2775\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7381 - accuracy: 0.0254 - val_loss: 1.7560 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7379 - accuracy: 0.0000e+00 - val_loss: 1.7568 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7382 - accuracy: 0.0000e+00 - val_loss: 1.7565 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7379 - accuracy: 0.0034 - val_loss: 1.7568 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7382 - accuracy: 3.7320e-04 - val_loss: 1.7566 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7381 - accuracy: 0.0368 - val_loss: 1.7562 - val_accuracy: 0.3510\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7378 - accuracy: 0.0621 - val_loss: 1.7577 - val_accuracy: 0.1916\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7382 - accuracy: 0.0403 - val_loss: 1.7560 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7375 - accuracy: 0.0541 - val_loss: 1.7566 - val_accuracy: 0.0125\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7376 - accuracy: 0.0021 - val_loss: 1.7595 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7378 - accuracy: 0.0000e+00 - val_loss: 1.7580 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7381 - accuracy: 3.7320e-04 - val_loss: 1.7568 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7380 - accuracy: 0.0147 - val_loss: 1.7562 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7380 - accuracy: 0.0000e+00 - val_loss: 1.7559 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7380 - accuracy: 0.0000e+00 - val_loss: 1.7562 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7376 - accuracy: 0.0000e+00 - val_loss: 1.7577 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7376 - accuracy: 0.0000e+00 - val_loss: 1.7575 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7439 - accuracy: 0.0131 - val_loss: 1.7566 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7373 - accuracy: 5.5981e-04 - val_loss: 1.7561 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7377 - accuracy: 0.0062 - val_loss: 1.7567 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7377 - accuracy: 0.0000e+00 - val_loss: 1.7563 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7378 - accuracy: 1.8660e-04 - val_loss: 1.7567 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7378 - accuracy: 0.0000e+00 - val_loss: 1.7563 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7374 - accuracy: 0.0000e+00 - val_loss: 1.7569 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7382 - accuracy: 0.0024 - val_loss: 1.7559 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7378 - accuracy: 0.0090 - val_loss: 1.7568 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7379 - accuracy: 0.0028 - val_loss: 1.7575 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7382 - accuracy: 0.0000e+00 - val_loss: 1.7563 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7377 - accuracy: 0.0000e+00 - val_loss: 1.7559 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7373 - accuracy: 0.0032 - val_loss: 1.7574 - val_accuracy: 0.1734\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7381 - accuracy: 0.0409 - val_loss: 1.7568 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7380 - accuracy: 0.0000e+00 - val_loss: 1.7567 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7377 - accuracy: 0.0108 - val_loss: 1.7565 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7376 - accuracy: 0.0022 - val_loss: 1.7562 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7383 - accuracy: 0.0063 - val_loss: 1.7564 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7376 - accuracy: 7.4641e-04 - val_loss: 1.7573 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7373 - accuracy: 0.0000e+00 - val_loss: 1.7565 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7375 - accuracy: 0.0095 - val_loss: 1.7572 - val_accuracy: 0.1621\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7395 - accuracy: 0.0481 - val_loss: 1.7560 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7377 - accuracy: 0.0000e+00 - val_loss: 1.7561 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7373 - accuracy: 0.0108 - val_loss: 1.7580 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7399 - accuracy: 0.0078 - val_loss: 1.7571 - val_accuracy: 0.3533\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7373 - accuracy: 0.2476 - val_loss: 1.7565 - val_accuracy: 0.0273\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7376 - accuracy: 0.0047 - val_loss: 1.7560 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7378 - accuracy: 0.0000e+00 - val_loss: 1.7560 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7379 - accuracy: 5.5981e-04 - val_loss: 1.7572 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7374 - accuracy: 0.0000e+00 - val_loss: 1.7579 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7374 - accuracy: 9.3301e-04 - val_loss: 1.7562 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7372 - accuracy: 0.0758 - val_loss: 1.7563 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7374 - accuracy: 0.0000e+00 - val_loss: 1.7562 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7378 - accuracy: 0.0179 - val_loss: 1.7562 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7379 - accuracy: 0.0689 - val_loss: 1.7570 - val_accuracy: 0.0337\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7389 - accuracy: 0.1198 - val_loss: 1.7560 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7371 - accuracy: 0.0955 - val_loss: 1.7580 - val_accuracy: 0.6017\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7375 - accuracy: 0.4512 - val_loss: 1.7563 - val_accuracy: 0.5562\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7375 - accuracy: 0.5400 - val_loss: 1.7580 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7376 - accuracy: 0.1502 - val_loss: 1.7563 - val_accuracy: 0.2942\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.7374 - accuracy: 0.3322 - val_loss: 1.7563 - val_accuracy: 0.4298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj8IJS2QsHXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trying with implimenting drop out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ot7XRHluXU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now trying to add more hidden layers to increase further accuracy 1st hidden layer with 10 nuerons\n",
        "classifier.add(Dense( units = 10 , kernel_initializer = 'uniform',activation = 'relu',input_dim =11))\n",
        "classifier.add(Dropout(0.30))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41Pnbb6cumY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2st hidden layer with 15 nuerons\n",
        "classifier.add(Dense( units = 15 , kernel_initializer = 'uniform',activation = 'relu'))\n",
        "classifier.add(Dropout(0.40))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT5MoveEuxCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3rd hidden layer with 10 nuerons\n",
        "classifier.add(Dense( units = 10 , kernel_initializer = 'uniform',activation = 'relu'))\n",
        "classifier.add(Dropout(0.30))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU75G_g-u3dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyPXXWSVu-zO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5acb690-659c-47c7-d2ab-5ad4e8f5680d"
      },
      "source": [
        "\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "model_history3=classifier.fit(x_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.9098 - accuracy: 0.0564 - val_loss: 1.0885 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.4548 - accuracy: 0.1021 - val_loss: 0.5657 - val_accuracy: 0.0254\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.3419 - accuracy: 0.1416 - val_loss: 0.5172 - val_accuracy: 0.0473\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.3013 - accuracy: 0.1715 - val_loss: 0.4878 - val_accuracy: 0.2052\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2784 - accuracy: 0.1515 - val_loss: 0.4748 - val_accuracy: 0.1723\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2687 - accuracy: 0.1056 - val_loss: 0.4536 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2453 - accuracy: 0.0758 - val_loss: 0.4357 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2189 - accuracy: 0.0435 - val_loss: 0.4167 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2157 - accuracy: 0.0353 - val_loss: 0.4139 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2221 - accuracy: 0.0340 - val_loss: 0.4147 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2477 - accuracy: 0.0336 - val_loss: 0.4224 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2028 - accuracy: 0.0295 - val_loss: 0.4176 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2179 - accuracy: 0.0321 - val_loss: 0.4079 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2112 - accuracy: 0.0362 - val_loss: 0.3989 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2187 - accuracy: 0.0446 - val_loss: 0.4102 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2187 - accuracy: 0.0539 - val_loss: 0.4069 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2165 - accuracy: 0.0502 - val_loss: 0.4119 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2098 - accuracy: 0.0539 - val_loss: 0.4000 - val_accuracy: 0.0371\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2311 - accuracy: 0.0411 - val_loss: 0.4131 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2108 - accuracy: 0.0634 - val_loss: 0.4186 - val_accuracy: 0.0716\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2271 - accuracy: 0.0569 - val_loss: 0.4156 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1883 - accuracy: 0.0726 - val_loss: 0.4000 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2017 - accuracy: 0.0666 - val_loss: 0.4035 - val_accuracy: 0.0890\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1999 - accuracy: 0.0648 - val_loss: 0.4047 - val_accuracy: 0.1219\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1846 - accuracy: 0.0504 - val_loss: 0.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2300 - accuracy: 0.0550 - val_loss: 0.3979 - val_accuracy: 0.0057\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2022 - accuracy: 0.0724 - val_loss: 0.4072 - val_accuracy: 0.0700\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2029 - accuracy: 0.1000 - val_loss: 0.4039 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2151 - accuracy: 0.0918 - val_loss: 0.4001 - val_accuracy: 0.2086\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2285 - accuracy: 0.0950 - val_loss: 0.4128 - val_accuracy: 0.0655\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2032 - accuracy: 0.0687 - val_loss: 0.4042 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2044 - accuracy: 0.0593 - val_loss: 0.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1937 - accuracy: 0.1538 - val_loss: 0.4097 - val_accuracy: 0.1530\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2377 - accuracy: 0.0567 - val_loss: 0.3995 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2124 - accuracy: 0.0522 - val_loss: 0.3959 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2059 - accuracy: 0.0819 - val_loss: 0.4028 - val_accuracy: 0.0674\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2168 - accuracy: 0.0963 - val_loss: 0.4045 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2109 - accuracy: 0.0493 - val_loss: 0.4066 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2029 - accuracy: 0.0381 - val_loss: 0.4116 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2159 - accuracy: 0.0541 - val_loss: 0.4041 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1996 - accuracy: 0.0494 - val_loss: 0.4031 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1989 - accuracy: 0.0864 - val_loss: 0.4062 - val_accuracy: 0.0299\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1917 - accuracy: 0.0674 - val_loss: 0.4015 - val_accuracy: 0.0545\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1909 - accuracy: 0.0927 - val_loss: 0.4095 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2104 - accuracy: 0.1000 - val_loss: 0.3995 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2004 - accuracy: 0.1278 - val_loss: 0.4067 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2284 - accuracy: 0.0940 - val_loss: 0.4136 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2167 - accuracy: 0.0829 - val_loss: 0.4086 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1894 - accuracy: 0.1575 - val_loss: 0.3997 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2079 - accuracy: 0.0552 - val_loss: 0.3921 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2167 - accuracy: 0.0360 - val_loss: 0.4040 - val_accuracy: 0.1162\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2329 - accuracy: 0.0521 - val_loss: 0.4032 - val_accuracy: 0.0666\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2108 - accuracy: 0.0390 - val_loss: 0.3919 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2104 - accuracy: 0.0407 - val_loss: 0.3900 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2200 - accuracy: 0.0390 - val_loss: 0.4060 - val_accuracy: 0.1034\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2320 - accuracy: 0.0442 - val_loss: 0.4098 - val_accuracy: 0.1227\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1813 - accuracy: 0.0767 - val_loss: 0.4058 - val_accuracy: 0.0984\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2200 - accuracy: 0.0651 - val_loss: 0.4038 - val_accuracy: 0.0765\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1972 - accuracy: 0.0651 - val_loss: 0.4013 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1989 - accuracy: 0.0702 - val_loss: 0.3925 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1967 - accuracy: 0.0569 - val_loss: 0.3909 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2293 - accuracy: 0.0396 - val_loss: 0.4018 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2084 - accuracy: 0.0282 - val_loss: 0.3980 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1953 - accuracy: 0.0237 - val_loss: 0.3985 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1988 - accuracy: 0.0230 - val_loss: 0.4229 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2075 - accuracy: 0.0246 - val_loss: 0.4081 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1928 - accuracy: 0.0289 - val_loss: 0.3982 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2203 - accuracy: 0.0933 - val_loss: 0.4193 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2018 - accuracy: 0.0756 - val_loss: 0.4018 - val_accuracy: 0.3431\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2194 - accuracy: 0.2387 - val_loss: 0.3979 - val_accuracy: 0.2764\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2015 - accuracy: 0.1560 - val_loss: 0.4133 - val_accuracy: 0.3230\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2148 - accuracy: 0.1450 - val_loss: 0.4339 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2151 - accuracy: 0.2375 - val_loss: 0.4024 - val_accuracy: 0.3745\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2184 - accuracy: 0.3004 - val_loss: 0.3991 - val_accuracy: 0.4801\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1969 - accuracy: 0.2782 - val_loss: 0.3976 - val_accuracy: 0.6819\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2419 - accuracy: 0.2777 - val_loss: 0.4002 - val_accuracy: 0.5199\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1831 - accuracy: 0.2390 - val_loss: 0.4214 - val_accuracy: 0.6335\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2202 - accuracy: 0.3532 - val_loss: 0.4002 - val_accuracy: 0.4589\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1910 - accuracy: 0.2362 - val_loss: 0.3931 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2115 - accuracy: 0.0892 - val_loss: 0.3941 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1821 - accuracy: 0.0659 - val_loss: 0.4078 - val_accuracy: 0.1829\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1955 - accuracy: 0.0853 - val_loss: 0.3978 - val_accuracy: 0.2537\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2153 - accuracy: 0.1762 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2151 - accuracy: 0.0521 - val_loss: 0.4035 - val_accuracy: 0.0401\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2180 - accuracy: 0.0728 - val_loss: 0.4163 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2325 - accuracy: 0.0355 - val_loss: 0.4084 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1928 - accuracy: 0.0239 - val_loss: 0.4028 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1909 - accuracy: 0.0317 - val_loss: 0.4016 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2246 - accuracy: 0.0414 - val_loss: 0.3956 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1968 - accuracy: 0.0340 - val_loss: 0.3974 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1923 - accuracy: 0.0418 - val_loss: 0.4024 - val_accuracy: 0.0731\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1901 - accuracy: 0.0679 - val_loss: 0.3980 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2073 - accuracy: 0.0707 - val_loss: 0.4194 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1848 - accuracy: 0.0149 - val_loss: 0.3997 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1869 - accuracy: 0.0418 - val_loss: 0.4100 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2115 - accuracy: 0.2334 - val_loss: 0.3981 - val_accuracy: 0.3412\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2135 - accuracy: 0.1461 - val_loss: 0.3981 - val_accuracy: 0.0909\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.2047 - accuracy: 0.0739 - val_loss: 0.4103 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1995 - accuracy: 0.0403 - val_loss: 0.4072 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 1.1974 - accuracy: 0.1579 - val_loss: 0.3990 - val_accuracy: 0.3226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxF6b8ECu_dU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0b2ebb4-2dff-4b2b-d126-30ba8a489ad5"
      },
      "source": [
        "# list all data in history\n",
        "\n",
        "print(model_history.history.keys())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYx9FnLZzZMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4bf2cb09-b7ea-4ce3-8c8a-b3a53b5642c9"
      },
      "source": [
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_vVhQIMzbsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Rsev841pAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}